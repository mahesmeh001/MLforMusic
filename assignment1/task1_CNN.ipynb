{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "TASK 1: For this task you are required to process a midi file and predict which composer wrote the piece of music. This task is evaluated\n",
    "based on accuracy (percentage of correct predictions).\n",
    "\n",
    "Try: CNN based Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "365d89d443f65455"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:02:28.780322Z",
     "start_time": "2025-05-08T00:02:27.493874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Probably more imports than are really necessary...\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import miditoolkit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def accuracy1(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T23:23:09.401727Z",
     "start_time": "2025-05-07T23:23:09.394083Z"
    }
   },
   "id": "4a81a8214c46e4e8",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataroot1 = \"data/student_files/task1_composer_classification/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:02:15.172997Z",
     "start_time": "2025-05-08T00:02:15.170558Z"
    }
   },
   "id": "57f7725253a006ad",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class model1():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def features(self, path):\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
    "        notes = midi_obj.instruments[0].notes\n",
    "        num_notes = len(notes)\n",
    "        average_pitch = sum([note.pitch for note in notes]) / num_notes\n",
    "        average_duration = sum([note.end - note.start for note in notes]) / num_notes\n",
    "        features = [average_pitch, average_duration]\n",
    "        return features\n",
    "    \n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "        for k in d:\n",
    "            x = self.features(k)\n",
    "            pred = self.model.predict([x])\n",
    "            predictions[k] = str(pred[0])\n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions\n",
    "\n",
    "    # Train your model. Note that this function will not be called from the autograder:\n",
    "    # instead you should upload your saved model using save()\n",
    "    def train(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            train_json = eval(f.read())\n",
    "        X_train = [self.features(k) for k in train_json]\n",
    "        y_train = [train_json[k] for k in train_json]\n",
    "        \n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        self.model = model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T23:23:09.406733Z",
     "start_time": "2025-05-07T23:23:09.402530Z"
    }
   },
   "id": "75259b79043412a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run1():\n",
    "    model = model1()\n",
    "    model.train(dataroot1 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "    acc1 = accuracy1(train_labels, train_preds)\n",
    "    print(\"Task 1 training accuracy = \" + str(acc1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T23:23:10.661993Z",
     "start_time": "2025-05-07T23:23:10.654529Z"
    }
   },
   "id": "37995c2bbe95759b",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Custom Model "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83ae1a2b10f10d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def create_artist_mapping(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        midi_to_artist = ast.literal_eval(f.read())\n",
    "        \n",
    "\n",
    "    unique_artists = sorted(set(midi_to_artist.values()))\n",
    "    id_to_artist = {i: artist for i, artist in enumerate(unique_artists)}\n",
    "\n",
    "    \n",
    "    return id_to_artist\n",
    "idToArtist = create_artist_mapping(\"data/student_files/task1_composer_classification/train.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:02:17.300300Z",
     "start_time": "2025-05-08T00:02:17.289946Z"
    }
   },
   "id": "1eb051a850ec9ec0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "{0: 'Bach', 1: 'Beethoven', 2: 'Chopin', 3: 'Haydn', 4: 'Liszt', 5: 'Mozart', 6: 'Schubert', 7: 'Schumann'}\n",
      "{'Bach': 0, 'Beethoven': 1, 'Chopin': 2, 'Haydn': 3, 'Liszt': 4, 'Mozart': 5, 'Schubert': 6, 'Schumann': 7}\n"
     ]
    }
   ],
   "source": [
    "print(len(idToArtist))\n",
    "print(idToArtist)\n",
    "\n",
    "artistToId={}\n",
    "for key,value in idToArtist.items():\n",
    "    artistToId[value] = key\n",
    "print(artistToId)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:02:18.557578Z",
     "start_time": "2025-05-08T00:02:18.555095Z"
    }
   },
   "id": "8021ccd014c5168b",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def save_model(model, filepath='sol_1.pt'):\n",
    "    \"\"\"Save a PyTorch model to a file\"\"\"\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "def load_model(model_class, filepath='sol_1.pt', *args, **kwargs):\n",
    "    \"\"\"Load a PyTorch model from a file\"\"\"\n",
    "    model = model_class(*args, **kwargs)  # instantiate the model\n",
    "    model.load_state_dict(torch.load(filepath))\n",
    "    model.eval()  # optional: sets dropout/batchnorm to eval mode\n",
    "    print(f\"Model loaded from {filepath}\")\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:02:20.558611Z",
     "start_time": "2025-05-08T00:02:20.554032Z"
    }
   },
   "id": "f51285f1e304fee5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wv/j6ybhf8906j4bmnp171wtn680000gn/T/ipykernel_34045/656406265.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X = [torch.tensor(features(key), dtype=torch.float32) for key, value in train_json.items()]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.8038e+01, -5.1450e+01, -5.8416e+01,  ..., -4.3110e-01,\n",
      "          1.1619e+00,  2.4942e+00],\n",
      "        [-4.1819e+01, -4.0434e+01, -3.8540e+01,  ..., -1.4225e+00,\n",
      "          3.4195e-02,  1.0889e+00],\n",
      "        [-3.9575e+01, -3.8109e+01, -3.7030e+01,  ..., -2.7528e+00,\n",
      "         -1.8523e+00, -1.3869e+00],\n",
      "        ...,\n",
      "        [-6.1445e+01, -6.1445e+01, -6.1445e+01,  ..., -6.1445e+01,\n",
      "         -6.1445e+01, -3.8426e+01],\n",
      "        [-6.1445e+01, -6.1445e+01, -6.1445e+01,  ..., -6.1445e+01,\n",
      "         -6.1445e+01, -4.2374e+01],\n",
      "        [-6.1445e+01, -6.1445e+01, -6.1445e+01,  ..., -6.1445e+01,\n",
      "         -6.1445e+01, -4.4460e+01]])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "from mido import MidiFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import islice\n",
    "import fluidsynth\n",
    "\n",
    "SAMPLE_RATE = 25000\n",
    "\n",
    "# create train loader \n",
    "\n",
    "def extract_waveform(path):\n",
    "    # Your code here\n",
    "    wave, sr = librosa.load(path, sr=SAMPLE_RATE)\n",
    "    return wave \n",
    "\n",
    "def extract_spec(w):\n",
    "    # Your code here\n",
    "    # load\n",
    "    stft = librosa.stft(y=w)\n",
    "    # take squared absolute values\n",
    "    spec = np.abs(stft) ** 2\n",
    "    \n",
    "    return torch.FloatTensor(spec)\n",
    "\n",
    "def extract_q(w):\n",
    "    # Your code here\n",
    "    result = librosa.cqt(y=w, sr=SAMPLE_RATE)\n",
    "    result = librosa.amplitude_to_db(np.abs(result))\n",
    "    \n",
    "    return torch.FloatTensor(result)\n",
    "\n",
    "def pad_or_truncate(spec, max_time=2048):\n",
    "    freq_bins, time_bins = spec.shape\n",
    "    if time_bins > max_time:\n",
    "        return spec[:, :max_time]\n",
    "    elif time_bins < max_time:\n",
    "        pad_width = max_time - time_bins\n",
    "        return F.pad(spec, (0, pad_width), mode='constant', value=0)\n",
    "    return spec\n",
    "\n",
    "\n",
    "import pretty_midi\n",
    "\n",
    "def features(path):\n",
    "    # https://medium.com/composer-style-classification-using-deep-learning/composer-style-classification-using-deep-learning-6bab64490995\n",
    "    #Spectral Centroid, Zero Crossing Rate, Chroma Frequencies, and Spectral Roll-off\n",
    "    \n",
    "    \"\"\"Extract robust features from all MIDI tracks for composer classification.\"\"\"\n",
    "    full_path = dataroot1 + '/' + path\n",
    "    \n",
    "    midi_obj = pretty_midi.PrettyMIDI(full_path)\n",
    "    \n",
    "    # Synthesize to waveform\n",
    "    w = midi_obj.fluidsynth()  # returns np array of audio\n",
    "    \n",
    "    # spec = extract_spec(w) # -> gets .320 and very slow \n",
    "    q = extract_q(w) #-> gets .850\n",
    "    \n",
    "    feature = pad_or_truncate(q, max_time=1000)\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def create_train_features(size=None, val_split=0.2):\n",
    "    # Load data\n",
    "    with open(dataroot1 + \"/train.json\", 'r') as f:\n",
    "        train_json = eval(f.read())\n",
    "    \n",
    "    # Limit size if specified\n",
    "    if size is not None:\n",
    "        train_json = dict(list(train_json.items())[:size])\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = [torch.tensor(features(key), dtype=torch.float32) for key, value in train_json.items()]\n",
    "    Y = [artistToId[value] for key, value in train_json.items()]\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    X = torch.stack(X)\n",
    "    Y = torch.tensor(Y, dtype=torch.int64)\n",
    "    \n",
    "    # Return all data if no validation split needed\n",
    "    if val_split <= 0:\n",
    "        return X, Y\n",
    "    \n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "        X, Y, test_size=val_split, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "    \n",
    "    \n",
    "X_train, y_train, X_val, y_val = create_train_features()\n",
    "\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:39:52.556385Z",
     "start_time": "2025-05-08T00:35:16.147122Z"
    }
   },
   "id": "90c4c5c466e04515",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "feature_size = (len(X_train[0]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:39:52.560094Z",
     "start_time": "2025-05-08T00:39:52.540019Z"
    }
   },
   "id": "d34bd676d4b4bef3",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:39:52.580570Z",
     "start_time": "2025-05-08T00:39:52.549921Z"
    }
   },
   "id": "27edf1843d4b8595",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "\n",
    "CLASSES = 8\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 256, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.pool4 = nn.AdaptiveAvgPool2d((1, 1))  # Global avg pool to flatten\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [B, 1, H, W]\n",
    "        x = self.pool1(nnF.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(nnF.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(nnF.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(nnF.relu(self.bn4(self.conv4(x))))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # x = nnF.relu(self.fc1(x))\n",
    "        x = self.dropout(nnF.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:48:17.488749Z",
     "start_time": "2025-05-08T00:48:17.142915Z"
    }
   },
   "id": "6c9de7ea9cb5ec2e",
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "class model2():\n",
    "    def __init__(self):\n",
    "        self.model = CNNClassifier()\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "        return\n",
    "    \n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "        for k in d:\n",
    "            x = (torch.tensor(features(k), dtype=torch.float32))\n",
    "            pred = self.model.predict([x])\n",
    "            predictions[k] = str(idToArtist[pred[0]])\n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions\n",
    "\n",
    "    # Train your model. Note that this function will not be called from the autograder:\n",
    "    # instead you should upload your saved model using save()\n",
    "    import torch\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=5):\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "        # device = \"cpu\"\n",
    "\n",
    "        model = self.model\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()  \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=.9, patience=3)\n",
    "        \n",
    "    \n",
    "        train_acc = []\n",
    "        val_acc = []\n",
    "    \n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        patience=15\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_train += batch_y.size(0)\n",
    "                correct_train += (predicted == batch_y).sum().item()\n",
    "    \n",
    "            train_accuracy = correct_train / total_train\n",
    "            train_acc.append(train_accuracy)\n",
    "    \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_x, batch_y in val_loader:\n",
    "                    batch_x = batch_x.to(device)\n",
    "                    batch_y = batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_x)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total_val += batch_y.size(0)\n",
    "                    correct_val += (predicted == batch_y).sum().item()\n",
    "    \n",
    "            val_accuracy = correct_val / total_val\n",
    "            val_acc.append(val_accuracy)\n",
    "            \n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}, LR: {optimizer.param_groups[0][\"lr\"]}')\n",
    "    \n",
    "            # Step the LR scheduler\n",
    "            scheduler.step(val_accuracy)\n",
    "    \n",
    "            # Early Stopping\n",
    "            if val_accuracy > best_val_acc:\n",
    "                best_val_acc = val_accuracy\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict()  # Save best model\n",
    "                save_model(model, 'sol_1_CNN.pt')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "    \n",
    "        # Load best model state\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "        self.train_acc = train_acc\n",
    "        self.val_acc = val_acc\n",
    "        self.model = model\n",
    "                \n",
    "    def get_train_acc(self):\n",
    "        return self.train_acc, self.val_acc\n",
    "    \n",
    "    def _get_model_copy(self, model):\n",
    "        \"\"\"Create a deep copy of the model.\"\"\"\n",
    "        model_copy = type(model)(*model.__init_args__, **model.__init_kwargs__)\n",
    "        model_copy.load_state_dict(model.state_dict())\n",
    "        return model_copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T00:48:18.155806Z",
     "start_time": "2025-05-08T00:48:18.146600Z"
    }
   },
   "id": "e5df887fd03f94ad",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Accuracy: 0.3781, Validation Accuracy: 0.4504, LR: 0.001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [2/100], Train Accuracy: 0.4349, Validation Accuracy: 0.2025, LR: 0.001\n",
      "Epoch [3/100], Train Accuracy: 0.4514, Validation Accuracy: 0.4174, LR: 0.001\n",
      "Epoch [4/100], Train Accuracy: 0.4752, Validation Accuracy: 0.4711, LR: 0.001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [5/100], Train Accuracy: 0.4855, Validation Accuracy: 0.5041, LR: 0.001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [6/100], Train Accuracy: 0.5021, Validation Accuracy: 0.4587, LR: 0.001\n",
      "Epoch [7/100], Train Accuracy: 0.5207, Validation Accuracy: 0.4835, LR: 0.001\n",
      "Epoch [8/100], Train Accuracy: 0.5207, Validation Accuracy: 0.3347, LR: 0.001\n",
      "Epoch [9/100], Train Accuracy: 0.5382, Validation Accuracy: 0.3636, LR: 0.001\n",
      "Epoch [10/100], Train Accuracy: 0.5300, Validation Accuracy: 0.5372, LR: 0.0009000000000000001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [11/100], Train Accuracy: 0.5465, Validation Accuracy: 0.4669, LR: 0.0009000000000000001\n",
      "Epoch [12/100], Train Accuracy: 0.5486, Validation Accuracy: 0.4628, LR: 0.0009000000000000001\n",
      "Epoch [13/100], Train Accuracy: 0.5744, Validation Accuracy: 0.4463, LR: 0.0009000000000000001\n",
      "Epoch [14/100], Train Accuracy: 0.5702, Validation Accuracy: 0.3264, LR: 0.0009000000000000001\n",
      "Epoch [15/100], Train Accuracy: 0.5909, Validation Accuracy: 0.3884, LR: 0.0008100000000000001\n",
      "Epoch [16/100], Train Accuracy: 0.5981, Validation Accuracy: 0.5083, LR: 0.0008100000000000001\n",
      "Epoch [17/100], Train Accuracy: 0.5785, Validation Accuracy: 0.5455, LR: 0.0008100000000000001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [18/100], Train Accuracy: 0.6023, Validation Accuracy: 0.4298, LR: 0.0008100000000000001\n",
      "Epoch [19/100], Train Accuracy: 0.6198, Validation Accuracy: 0.5248, LR: 0.0008100000000000001\n",
      "Epoch [20/100], Train Accuracy: 0.6302, Validation Accuracy: 0.1694, LR: 0.0008100000000000001\n",
      "Epoch [21/100], Train Accuracy: 0.6508, Validation Accuracy: 0.3760, LR: 0.0008100000000000001\n",
      "Epoch [22/100], Train Accuracy: 0.6488, Validation Accuracy: 0.5165, LR: 0.000729\n",
      "Epoch [23/100], Train Accuracy: 0.6746, Validation Accuracy: 0.4669, LR: 0.000729\n",
      "Epoch [24/100], Train Accuracy: 0.6808, Validation Accuracy: 0.2851, LR: 0.000729\n",
      "Epoch [25/100], Train Accuracy: 0.6581, Validation Accuracy: 0.4876, LR: 0.000729\n",
      "Epoch [26/100], Train Accuracy: 0.7045, Validation Accuracy: 0.5537, LR: 0.0006561000000000001\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [27/100], Train Accuracy: 0.7014, Validation Accuracy: 0.4298, LR: 0.0006561000000000001\n",
      "Epoch [28/100], Train Accuracy: 0.7324, Validation Accuracy: 0.5165, LR: 0.0006561000000000001\n",
      "Epoch [29/100], Train Accuracy: 0.7283, Validation Accuracy: 0.5331, LR: 0.0006561000000000001\n",
      "Epoch [30/100], Train Accuracy: 0.7118, Validation Accuracy: 0.4917, LR: 0.0006561000000000001\n",
      "Epoch [31/100], Train Accuracy: 0.7417, Validation Accuracy: 0.5785, LR: 0.00059049\n",
      "Model saved to sol_1_CNN.pt\n",
      "Epoch [32/100], Train Accuracy: 0.7624, Validation Accuracy: 0.4545, LR: 0.00059049\n",
      "Epoch [33/100], Train Accuracy: 0.7366, Validation Accuracy: 0.4380, LR: 0.00059049\n",
      "Epoch [34/100], Train Accuracy: 0.7758, Validation Accuracy: 0.4256, LR: 0.00059049\n",
      "Epoch [35/100], Train Accuracy: 0.7903, Validation Accuracy: 0.4835, LR: 0.00059049\n",
      "Epoch [36/100], Train Accuracy: 0.8037, Validation Accuracy: 0.3926, LR: 0.000531441\n",
      "Epoch [37/100], Train Accuracy: 0.8130, Validation Accuracy: 0.3264, LR: 0.000531441\n",
      "Epoch [38/100], Train Accuracy: 0.8223, Validation Accuracy: 0.5083, LR: 0.000531441\n",
      "Epoch [39/100], Train Accuracy: 0.8202, Validation Accuracy: 0.4463, LR: 0.000531441\n",
      "Epoch [40/100], Train Accuracy: 0.8492, Validation Accuracy: 0.4091, LR: 0.0004782969\n",
      "Epoch [41/100], Train Accuracy: 0.8616, Validation Accuracy: 0.5785, LR: 0.0004782969\n",
      "Epoch [42/100], Train Accuracy: 0.8977, Validation Accuracy: 0.4504, LR: 0.0004782969\n",
      "Epoch [43/100], Train Accuracy: 0.8636, Validation Accuracy: 0.4959, LR: 0.0004782969\n",
      "Epoch [44/100], Train Accuracy: 0.8523, Validation Accuracy: 0.4132, LR: 0.00043046721\n",
      "Epoch [45/100], Train Accuracy: 0.8709, Validation Accuracy: 0.3223, LR: 0.00043046721\n",
      "Epoch [46/100], Train Accuracy: 0.8998, Validation Accuracy: 0.5207, LR: 0.00043046721\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model = model2()\n",
    "model.train(train_loader, val_loader, EPOCHS)\n",
    "\n",
    "\n",
    "# train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "# test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "# \n",
    "# train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "# acc1 = accuracy1(train_labels, train_preds)\n",
    "# print(\"Task 1 training accuracy = \" + str(acc1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-08T01:10:01.151564Z",
     "start_time": "2025-05-08T00:48:18.924884Z"
    }
   },
   "id": "c179b4e57e8ca203",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc, val_acc = model.get_train_acc()\n",
    "\n",
    "x = range(1, EPOCHS + 1)\n",
    "\n",
    "# Plot training accuracy\n",
    "plt.plot(x, train_acc, label='Training Accuracy', color='blue', linestyle='-', marker='o')\n",
    "\n",
    "# Plot validation accuracy\n",
    "plt.plot(x, val_acc, label='Validation Accuracy', color='red', linestyle='--', marker='x')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy per Epoch')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-05-07T23:58:06.159146Z"
    }
   },
   "id": "3f5934c6ae1de768",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('fullTrainData.pkl', 'wb') as f:\n",
    "    data = {'train_loader': train_loader, 'val_loader':val_loader, 'train_dataset': train_dataset, 'val_dataset':val_dataset}\n",
    "    pickle.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-07T21:23:46.424405Z",
     "start_time": "2025-05-07T21:23:46.415515Z"
    }
   },
   "id": "6c6a974b5c41f249",
   "execution_count": 65
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
