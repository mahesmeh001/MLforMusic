{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Sine wave generation and binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A - Sine Wave Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "To complete this part, install the required Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:28:14.278163Z",
     "start_time": "2025-04-07T22:28:13.014861Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "from mido import MidiFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (installation process may be different on your system)\n",
    "# You don't need to use these libraries, so long as you implement the specified functions\n",
    "# !pip install numpy\n",
    "# !pip install scipy\n",
    "# !pip install IPython\n",
    "# !pip install glob\n",
    "# !pip install scikit-learn\n",
    "# !pip install mido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function that converts a musical note name to its corresponding frequency in Hertz (Hz)\n",
    "\n",
    "`note_name_to_frequency()`\n",
    "- **Input**: A string `note_name` combining a note (e.g., `'C'`, `'C#'`, `'D'`, `'D#'`, `'E'`, `'F'`, `'F#'`, `'G'`, `'G#'`, `'A'`, `'A#'`, `'B'`) and an octave number (`'0'` to `'10'`)\n",
    "- **Output**: A float representing the frequency in Hz\n",
    "- **Details**:\n",
    "  - Use A4 = 440 Hz as the reference frequency\n",
    "  - Frequencies double with each octave increase (e.g., A5 = 880 Hz) and halve with each decrease (e.g., A3 = 220 Hz)\n",
    "\n",
    "- **Examples**:\n",
    "  - `'A4'` → `440.0`\n",
    "  - `'A3'` → `220.0`\n",
    "  - `'G#4'` → `415.3047`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:29:25.787780Z",
     "start_time": "2025-04-07T22:29:25.781582Z"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "NOTES = ['C', 'C#', 'D', 'D#', 'E', 'F', \n",
    "             'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "def note_name_to_frequency(note_name):\n",
    "    import math\n",
    "\n",
    "    # Reference: A4 = 440 Hz\n",
    "    A4_FREQ = 440.0\n",
    "    A4_INDEX = 9 + 12 * 4  # A is the 10th note (index 9) in the chromatic scale, octave 4\n",
    "    \n",
    "    # Extract the note and octave from the input\n",
    "    for i in range(1, len(note_name)):\n",
    "        if note_name[i].isdigit():\n",
    "            note = note_name[:i]\n",
    "            octave = int(note_name[i:])\n",
    "            break\n",
    "\n",
    "    if note not in NOTES:\n",
    "        raise ValueError(f\"Invalid note name: {note}\")\n",
    "\n",
    "    note_index = NOTES.index(note)\n",
    "    semitone_diff = (octave * 12 + note_index) - A4_INDEX\n",
    "\n",
    "    # Compute frequency using the formula:\n",
    "    frequency = A4_FREQ * (2 ** (semitone_diff / 12))\n",
    "    return round(frequency, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that linearly decreases the amplitude of a given waveform\n",
    "\n",
    "`decrease_amplitude()`\n",
    "- **Inputs**:\n",
    "  - `audio`: A NumPy array representing the audio waveform at a sample rate of 44100 Hz\n",
    "- **Output**: A NumPy array representing the audio waveform at a sample rate of 44100 Hz\n",
    "- **Details**:\n",
    "  - The function must linearly decrease the amplitude of the input audio. The amplitude should start at 1 (full volume) and decrease gradually to 0 (silence) by the end of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrease_amplitude(audio):\n",
    "    # Q2: Your code goes here\n",
    "    fade = np.linspace(1, 0, len(audio))\n",
    "    return audio * fade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function that adds a delay effect to a given audio where the output is a combination of the original audio and a delayed audio\n",
    "\n",
    "`add_delay_effects()`  \n",
    "- **Inputs**:  \n",
    "  - `audio`: A NumPy array representing the audio waveform, sampled at 44,100 Hz\n",
    "- **Output**:  \n",
    "  - A NumPy array representing the modified audio waveform, sampled at 44,100 Hz\n",
    "- **Details**:\n",
    "  - The amplitude of the delayed audio should be 30% of the original audio's amplitude\n",
    "  - The amplitude of the original audio should be adjusted to 70% of the original audio's amplitude\n",
    "  - The output should combine the original audio (with the adjusted amplitude) with a delayed version of itself\n",
    "  - The delayed audio should be offset by 0.5 seconds behind the original audio\n",
    "\n",
    "- **Examples**:\n",
    "  - The provided files (input.wav and output.wav) provide examples of input and output audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use these for visualization if you like, though the autograder won't use ipython\n",
    "#\n",
    "# from IPython.display import Audio, display\n",
    "#\n",
    "# print(\"Example Input Audio:\")\n",
    "# display(Audio(filename = \"input.wav\", rate=44100))\n",
    "# \n",
    "# print(\"Example Output Audio:\")\n",
    "# display(Audio(filename = \"output.wav\", rate=44100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_delay_effects(audio, sample_rate = 44100):\n",
    "    #Q3: Your code goes here\n",
    "    delay_time = 0.5\n",
    "    delay = int(delay_time * sample_rate)\n",
    "    \n",
    "    delayed_audio = np.zeros(len(audio) + delay)\n",
    "    delayed_audio[delay:] += 0.3 * audio # delayed at 30%\n",
    "    delayed_audio[:len(audio)] += 0.7 * audio # original at 70%\n",
    "    return delayed_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write a function that concatenates a list of audio arrays sequentially and a function that mixes audio arrays by scaling and summing them, simulating simultaneous playback\n",
    "\n",
    "`concatenate_audio()`\n",
    "- **Input**:\n",
    "  - `list_of_your_audio`: A list of NumPy arrays (e.g., `[audio1, audio2]`), each representing audio at 44100 Hz\n",
    "- **Output**: A NumPy array of the concatenated audio\n",
    "- **Example**:\n",
    "  - If `audio1` is 2 seconds (88200 samples) and `audio2` is 1 second (44100 samples), the output is 3 seconds (132300 samples)\n",
    "\n",
    "`mix_audio()`\n",
    "- **Inputs**:\n",
    "  - `list_of_your_audio`: A list of NumPy arrays (e.g., `[audio1, audio2]`), all with the same length at 44100 Hz.\n",
    "  - `amplitudes`: A list of floats (e.g., `[0.2, 0.8]`) matching the length of `list_of_your_audio`\n",
    "- **Output**: A NumPy array representing the mixed audio\n",
    "- **Example**:\n",
    "  - If `audio1` and `audio2` are 2 seconds long, and `amplitudes = [0.2, 0.8]`, the output is `0.2 * audio1 + 0.8 * audio2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_audio(list_of_your_audio):\n",
    "    #Q4: Your code goes here\n",
    "    # just iterate through and sum each element?\n",
    "    return np.concatenate(list_of_your_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(list_of_your_audio, amplitudes):\n",
    "    #Q4: Your code goes here\n",
    "    # sum but according to the amplitude...\n",
    "    length = len(list_of_your_audio[0])\n",
    "    mixed_audio = np.zeros(length)\n",
    "    for audio, amp in zip(list_of_your_audio, amplitudes):\n",
    "        mixed_audio += amp*audio\n",
    "    return mixed_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Modify your solution to Q2 so that your pipeline can generate sawtooth waves by adding harmonics based on the following equation:\n",
    "\n",
    "    $\\text{sawtooth}(f, t) = \\frac{2}{\\pi} \\sum_{k=1}^{19} \\frac{(-1)^{k+1}}{k} \\sin(2\\pi k f t)$ \n",
    "\n",
    "- **Inputs**:\n",
    "  - `frequency`: Fundamental frequency of sawtooth wave\n",
    "  - `duration`: A float representing the duration in seconds (e.g., 2.0)\n",
    "- **Output**: A NumPy array representing the audio waveform at a sample rate of 44100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sawtooth_wave(frequency, duration, sample_rate=44100):\n",
    "    #Q5: Your code goes here \n",
    "    # basically use sawtooth instead of linear \n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)\n",
    "    \n",
    "    wave = np.zeros_like(t)\n",
    "    for k in range(1, 20):  # k from 1 to 19\n",
    "        wave += ((-1) ** (k + 1)) * (1 / k) * np.sin(2 * np.pi * k * frequency * t)\n",
    "    \n",
    "    wave *= 2 / np.pi\n",
    "\n",
    "    # Apply linearly decreasing amplitude envelope\n",
    "    fade = np.linspace(1, 0, len(wave))\n",
    "    return wave * fade\n",
    "    return wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B - Binary Classification\n",
    "Train a binary classification model using `scikit-learn` to distinguish between piano and drum MIDI files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unzip MIDI Files\n",
    "Extract the provided MIDI datasets:\n",
    "\n",
    "```bash\n",
    "unzip piano.zip\n",
    "unzip drums.zip\n",
    "```\n",
    "\n",
    "- `./piano`: Contains piano MIDI files (e.g., `0000.mid` to `2154.mid`)\n",
    "- `./drums`: Contains drum MIDI files (e.g., `0000.mid` to `2154.mid`)\n",
    "- Source: [Tegridy MIDI Dataset] (https://github.com/asigalov61/Tegridy-MIDI-Dataset)\n",
    "\n",
    "These folders should be extracted into the same directory as your solution file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Write functions to compute simple statistics about the files\n",
    "\n",
    "####  `get_stats()`\n",
    "\n",
    "- **Inputs**:\n",
    "  - `piano_file_paths`: List of piano MIDI file paths`\n",
    "  - `drum_file_paths`: List of drum MIDI file paths`\n",
    "- **Output**: A dictionary:\n",
    "  - `\"piano_midi_num\"`: Integer, number of piano files\n",
    "  - `\"drum_midi_num\"`: Integer, number of drum files\n",
    "  - `\"average_piano_beat_num\"`: Float, average number of beats in piano files\n",
    "  - `\"average_drum_beat_num\"`: Float, average number of beats in drum files\n",
    "- **Details**:\n",
    "  - For each file:\n",
    "    - Load with `MidiFile(file_path)`\n",
    "    - Get `ticks_per_beat` from `mid.ticks_per_beat`\n",
    "    - Compute total ticks as the maximum cumulative `msg.time` (delta time) across tracks\n",
    "    - Number of beats = (total ticks / ticks_per_beat)\n",
    "  - Compute averages, handling empty lists (return 0 if no files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lists():\n",
    "    piano_files = sorted(glob.glob(\"./piano/*.mid\"))\n",
    "    drum_files = sorted(glob.glob(\"./drums/*.mid\"))\n",
    "    return piano_files, drum_files\n",
    "\n",
    "def get_num_beats(file_path):\n",
    "    # Q6: Your code goes here\n",
    "    mid = MidiFile(file_path)\n",
    "    # Might need: mid.tracks, msg.time, mid.ticks_per_beat\n",
    "    \n",
    "    max_track_ticks = 0\n",
    "    for track in mid.tracks:\n",
    "        this_ticks = 0 \n",
    "        for msg in track:\n",
    "            this_ticks += msg.time\n",
    "        max_track_ticks = max(max_track_ticks, this_ticks)\n",
    "    \n",
    "    return max_track_ticks/mid.ticks_per_beat if mid.ticks_per_beat else 0\n",
    "    \n",
    "\n",
    "def get_stats(piano_path_list, drum_path_list):\n",
    "    piano_beat_nums = []\n",
    "    drum_beat_nums = []\n",
    "    for file_path in piano_path_list:\n",
    "        piano_beat_nums.append(get_num_beats(file_path))\n",
    "        \n",
    "    for file_path in drum_path_list:\n",
    "        drum_beat_nums.append(get_num_beats(file_path))\n",
    "    \n",
    "    return {\"piano_midi_num\":len(piano_path_list),\n",
    "            \"drum_midi_num\":len(drum_path_list),\n",
    "            \"average_piano_beat_num\":np.average(piano_beat_nums),\n",
    "            \"average_drum_beat_num\":np.average(drum_beat_nums)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Implement a few simple feature functions, to compute the lowest and highest MIDI note numbers in a file, and the set of unique notes in a file\n",
    "\n",
    "`get_lowest_pitch()` and `get_highest_pitch()`\n",
    "functions to find the lowest and highest MIDI note numbers in a file\n",
    "\n",
    "- **Input**: `file_path`, a string (e.g., `\"./piano/0000.mid\"`)\n",
    "- **Output**: An integer (0–127) or `None` if no notes exist\n",
    "- **Details**:\n",
    "  - Use `MidiFile(file_path)` and scan all tracks\n",
    "  - Check `msg.type == 'note_on'` and `msg.velocity > 0` for active notes\n",
    "  - Return the minimum (`get_lowest_pitch`) or maximum (`get_highest_pitch`) `msg.note`\n",
    "\n",
    "`get_unique_pitch_num()`\n",
    "a function to count unique MIDI note numbers in a file\n",
    "\n",
    "- **Input**: `file_path`, a string\n",
    "- **Output**: An integer, the number of unique pitches\n",
    "- **Details**:\n",
    "  - Collect `msg.note` from all `'note_on'` events with `msg.velocity > 0` into a set\n",
    "  - Return the set’s length\n",
    "- **Example**: For notes `[\"C4\", \"C4\", \"G4\", \"G4\", \"A4\", \"A4\", \"G4\"]`, output is 3 (unique: C4, G4, A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_pitch(file_path):\n",
    "    #Q7-1: Your code goes here\n",
    "    pass\n",
    "\n",
    "def get_highest_pitch(file_path):\n",
    "    #Q7-2: Your code goes here\n",
    "    pass\n",
    "\n",
    "def get_unique_pitch_num(file_path):\n",
    "    #Q7-3: Your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Implement an additional feature extraction function to compute the average MIDI note number in a file\n",
    "\n",
    "`get_average_pitch_value()`\n",
    "a function to return the average MIDI note number from a file\n",
    "\n",
    "- **Input**: `file_path`, a string\n",
    "- **Output**: A float, the average value of MIDI notes in the file\n",
    "- **Details**:\n",
    "  - Collect `msg.note` from all `'note_on'` events with `msg.velocity > 0` into a set\n",
    "- **Example**: For notes `[51, 52, 53]`, output is `52`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_pitch_value(file_path):\n",
    "    #Q8: Your code goes here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Construct your dataset and split it into train and test sets using `scikit-learn` (most of this code is provided). Train your model to classify whether a given file is intended for piano or drums.\n",
    "\n",
    "`featureQ9()`\n",
    "\n",
    "Returns a feature vector concatenating the four features described above\n",
    "\n",
    "- **Input**: `file_path`, a string.\n",
    "- **Output**: A vector of four features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ9(file_path):\n",
    "    # Already implemented: this one is a freebie if you got everything above correct!\n",
    "    return [get_lowest_pitch(file_path),\n",
    "            get_highest_pitch(file_path),\n",
    "            get_unique_pitch_num(file_path),\n",
    "            get_average_pitch_value(file_path)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Creatively incorporate additional features into your classifier to make your classification more accurate.  Include comments describing your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureQ10(file_path):\n",
    "    #Q10: Your code goes here\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
